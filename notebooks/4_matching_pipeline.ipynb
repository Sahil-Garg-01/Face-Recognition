{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa73e17",
   "metadata": {},
   "source": [
    "# Task 4: Matching Pipeline\n",
    "## Implement cosine similarity matching and evaluate identification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e8e169",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path('..').resolve()))\n",
    "from src.embedding import FaceEmbedder, EmbeddingDatabase\n",
    "from src.matching import FaceRecognitionMatcher, MatchingEvaluator\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116cf236",
   "metadata": {},
   "source": [
    "### 2. Setup Paths and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321e15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "BASE_PATH = Path('..').resolve()\n",
    "VALIDATION_PATH = BASE_PATH / 'data' / 'validation'\n",
    "DB_PATH = BASE_PATH / 'data' / 'embeddings.db'\n",
    "\n",
    "print(f\"Base path: {BASE_PATH}\")\n",
    "print(f\"Validation path: {VALIDATION_PATH}\")\n",
    "print(f\"Database path: {DB_PATH}\")\n",
    "print(f\"Database exists: {DB_PATH.exists()}\")\n",
    "\n",
    "# Load database\n",
    "db = EmbeddingDatabase(str(DB_PATH))\n",
    "stats = db.get_db_stats()\n",
    "\n",
    "print(f\"\\nDatabase loaded:\")\n",
    "print(f\"  Identities: {stats['total_identities']}\")\n",
    "print(f\"  Embeddings: {stats['total_embeddings']}\")\n",
    "\n",
    "# Load validation images\n",
    "val_images = sorted(list(VALIDATION_PATH.glob('*/*.jpg')) + list(VALIDATION_PATH.glob('*/*.png')))\n",
    "print(f\"\\nValidation images found: {len(val_images)}\")\n",
    "if val_images:\n",
    "    print(f\"Sample: {val_images[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471b682",
   "metadata": {},
   "source": [
    "### 3. Load Gallery Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b978bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all gallery embeddings from database\n",
    "all_embeddings = db.get_all_embeddings()\n",
    "\n",
    "print(f\"Gallery embeddings loaded:\")\n",
    "print(f\"  Identities: {len(all_embeddings)}\")\n",
    "\n",
    "total_embeddings = sum(len(v) for v in all_embeddings.values())\n",
    "print(f\"  Total embeddings: {total_embeddings}\")\n",
    "\n",
    "for identity, embeddings in list(all_embeddings.items())[:3]:\n",
    "    print(f\"  {identity}: {len(embeddings)} embeddings, shape {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1c271",
   "metadata": {},
   "source": [
    "### 4. Initialize Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa536a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize matcher with default threshold and top-K\n",
    "matcher = FaceRecognitionMatcher(\n",
    "    embeddings_dict=all_embeddings,\n",
    "    threshold=0.6,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(f\"Matcher initialized!\")\n",
    "print(f\"  Gallery size: {matcher.num_gallery} embeddings\")\n",
    "print(f\"  Threshold: {matcher.threshold}\")\n",
    "print(f\"  Top-K: {matcher.top_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a16bb",
   "metadata": {},
   "source": [
    "### 5. Extract Validation Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b5442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedder for validation images\n",
    "embedder = FaceEmbedder(model_name='vggface2')\n",
    "\n",
    "# Extract embeddings for validation images\n",
    "val_embeddings = []\n",
    "val_ground_truth = []\n",
    "failed_images = []\n",
    "\n",
    "print(f\"Extracting validation embeddings...\\n\")\n",
    "\n",
    "for val_img_path in tqdm(val_images, desc=\"Processing validation images\"):\n",
    "    try:\n",
    "        # Load image\n",
    "        img = cv2.imread(str(val_img_path))\n",
    "        if img is None:\n",
    "            failed_images.append(str(val_img_path))\n",
    "            continue\n",
    "        \n",
    "        # Extract embedding\n",
    "        embedding = embedder.extract_embedding(img)\n",
    "        \n",
    "        # Extract ground truth from path\n",
    "        identity_name = val_img_path.parent.name\n",
    "        \n",
    "        val_embeddings.append(embedding)\n",
    "        val_ground_truth.append(identity_name)\n",
    "    \n",
    "    except Exception as e:\n",
    "        failed_images.append(str(val_img_path))\n",
    "\n",
    "val_embeddings = np.array(val_embeddings)\n",
    "\n",
    "print(f\"\\n‚úì Extraction complete!\")\n",
    "print(f\"  Processed: {len(val_embeddings)} images\")\n",
    "print(f\"  Failed: {len(failed_images)}\")\n",
    "print(f\"  Embedding shape: {val_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e50d7a",
   "metadata": {},
   "source": [
    "### 6. Match Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match all validation embeddings\n",
    "print(\"Matching validation images...\\n\")\n",
    "\n",
    "matches = matcher.match_batch(val_embeddings)\n",
    "\n",
    "print(f\"‚úì Matching complete!\")\n",
    "\n",
    "# Extract predictions\n",
    "predictions = [m['identity'] for m in matches]\n",
    "confidences = [m['confidence'] for m in matches]\n",
    "\n",
    "# Show sample results\n",
    "print(f\"\\nSample matching results (first 5):\")\n",
    "for i in range(min(5, len(matches))):\n",
    "    match = matches[i]\n",
    "    gt = val_ground_truth[i]\n",
    "    correct = \"‚úì\" if match['identity'] == gt else \"‚úó\"\n",
    "    print(f\"{correct} Predicted: {match['identity']}, Ground Truth: {gt}, Confidence: {match['confidence']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93db0bd",
   "metadata": {},
   "source": [
    "### 7. Calculate Identification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59fcc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute overall accuracy\n",
    "accuracy = matcher.get_identification_accuracy(val_embeddings, val_ground_truth)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"IDENTIFICATION ACCURACY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Top-1 Accuracy: {accuracy['top_1_accuracy']:.4f} ({accuracy['top_1_accuracy']*100:.2f}%)\")\n",
    "print(f\"  Correct: {accuracy['top_1_correct']}/{accuracy['total_samples']}\")\n",
    "print(f\"\\nTop-5 Accuracy: {accuracy['top_5_accuracy']:.4f} ({accuracy['top_5_accuracy']*100:.2f}%)\")\n",
    "print(f\"  Correct: {accuracy['top_5_correct']}/{accuracy['total_samples']}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a504f4",
   "metadata": {},
   "source": [
    "### 8. Per-Identity Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf83d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-identity accuracy\n",
    "per_identity = matcher.get_per_identity_accuracy(val_embeddings, val_ground_truth)\n",
    "\n",
    "# Convert to dataframe\n",
    "identity_data = []\n",
    "for identity, stats in sorted(per_identity.items()):\n",
    "    identity_data.append({\n",
    "        'Identity': identity,\n",
    "        'Total': stats['total'],\n",
    "        'Top-1 Correct': stats['top_1_correct'],\n",
    "        'Top-1 Accuracy': stats['top_1_accuracy'],\n",
    "        'Top-5 Correct': stats['top_5_correct'],\n",
    "        'Top-5 Accuracy': stats['top_5_accuracy']\n",
    "    })\n",
    "\n",
    "df_per_identity = pd.DataFrame(identity_data)\n",
    "\n",
    "print(\"Per-Identity Results:\")\n",
    "print(df_per_identity.to_string(index=False))\n",
    "\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"  Mean Top-1 Accuracy: {df_per_identity['Top-1 Accuracy'].mean():.4f}\")\n",
    "print(f\"  Min Top-1 Accuracy: {df_per_identity['Top-1 Accuracy'].min():.4f}\")\n",
    "print(f\"  Max Top-1 Accuracy: {df_per_identity['Top-1 Accuracy'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047fe7e0",
   "metadata": {},
   "source": [
    "### 9. Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821f2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze different thresholds\n",
    "threshold_results = MatchingEvaluator.threshold_analysis(\n",
    "    confidences=confidences,\n",
    "    ground_truth=val_ground_truth,\n",
    "    predictions=predictions,\n",
    "    thresholds=np.linspace(0.3, 1.0, 15)\n",
    ")\n",
    "\n",
    "df_thresholds = pd.DataFrame(threshold_results)\n",
    "\n",
    "print(\"Threshold Analysis:\")\n",
    "print(df_thresholds.to_string(index=False))\n",
    "\n",
    "# Find optimal threshold (max accuracy with good coverage)\n",
    "optimal_idx = df_thresholds['accuracy'].idxmax()\n",
    "optimal_threshold = df_thresholds.loc[optimal_idx, 'threshold']\n",
    "optimal_accuracy = df_thresholds.loc[optimal_idx, 'accuracy']\n",
    "optimal_coverage = df_thresholds.loc[optimal_idx, 'coverage']\n",
    "\n",
    "print(f\"\\nOptimal Threshold: {optimal_threshold:.2f}\")\n",
    "print(f\"  Accuracy: {optimal_accuracy:.4f}\")\n",
    "print(f\"  Coverage: {optimal_coverage:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c7c704",
   "metadata": {},
   "source": [
    "### 10. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e72bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Per-identity top-1 accuracy\n",
    "axes[0, 0].barh(df_per_identity['Identity'], df_per_identity['Top-1 Accuracy'])\n",
    "axes[0, 0].set_xlabel('Top-1 Accuracy')\n",
    "axes[0, 0].set_title('Per-Identity Top-1 Accuracy')\n",
    "axes[0, 0].set_xlim([0, 1.1])\n",
    "axes[0, 0].grid(alpha=0.3, axis='x')\n",
    "\n",
    "# 2. Confidence distribution\n",
    "axes[0, 1].hist(confidences, bins=15, edgecolor='black')\n",
    "axes[0, 1].axvline(matcher.threshold, color='r', linestyle='--', linewidth=2, label=f'Current: {matcher.threshold}')\n",
    "axes[0, 1].set_xlabel('Confidence Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Confidence Distribution')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Threshold vs Accuracy/Coverage\n",
    "axes[1, 0].plot(df_thresholds['threshold'], df_thresholds['accuracy'], 'b-o', label='Accuracy', linewidth=2)\n",
    "axes[1, 0].plot(df_thresholds['threshold'], df_thresholds['coverage'], 'r-s', label='Coverage', linewidth=2)\n",
    "axes[1, 0].axvline(optimal_threshold, color='g', linestyle='--', linewidth=2, label=f'Optimal: {optimal_threshold:.2f}')\n",
    "axes[1, 0].set_xlabel('Threshold')\n",
    "axes[1, 0].set_ylabel('Rate')\n",
    "axes[1, 0].set_title('Threshold Analysis')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# 4. Accuracy summary\n",
    "axes[1, 1].axis('off')\n",
    "summary_text = f\"\"\"\n",
    "MATCHING SUMMARY\n",
    "{'='*40}\n",
    "\n",
    "Overall Performance:\n",
    "  Top-1 Accuracy: {accuracy['top_1_accuracy']*100:.2f}%\n",
    "  Top-5 Accuracy: {accuracy['top_5_accuracy']*100:.2f}%\n",
    "\n",
    "Threshold: {matcher.threshold}\n",
    "Top-K: {matcher.top_k}\n",
    "Gallery Size: {matcher.num_gallery} embeddings\n",
    "Test Size: {len(val_embeddings)} images\n",
    "\n",
    "Confidence Stats:\n",
    "  Min: {np.min(confidences):.4f}\n",
    "  Max: {np.max(confidences):.4f}\n",
    "  Mean: {np.mean(confidences):.4f}\n",
    "  Std: {np.std(confidences):.4f}\n",
    "\n",
    "Optimal Threshold: {optimal_threshold:.2f}\n",
    "  Accuracy: {optimal_accuracy*100:.2f}%\n",
    "  Coverage: {optimal_coverage*100:.2f}%\n",
    "\"\"\"\n",
    "axes[1, 1].text(0.05, 0.95, summary_text, fontsize=11, family='monospace',\n",
    "                verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa72e96",
   "metadata": {},
   "source": [
    "### 11. Detailed Matching Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedc4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed matches for all validation images\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED MATCHING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correct_count = 0\n",
    "for i, (match, gt) in enumerate(zip(matches, val_ground_truth), 1):\n",
    "    is_correct = match['identity'] == gt\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "    \n",
    "    status = \"‚úì CORRECT\" if is_correct else \"‚úó WRONG\"\n",
    "    print(f\"\\nImage {i}: {status}\")\n",
    "    print(f\"  Ground Truth: {gt}\")\n",
    "    print(f\"  Top-1 Match: {match['identity']} (confidence: {match['confidence']:.4f})\")\n",
    "    print(f\"  Matched: {'Yes' if match['matched'] else 'No'}\")\n",
    "    print(f\"  Inference time: {match['inference_time_ms']:.2f} ms\")\n",
    "    \n",
    "    print(f\"  Top-5 Matches:\")\n",
    "    for j, top_match in enumerate(match['top_k_matches'][:5], 1):\n",
    "        print(f\"    {j}. {top_match['identity']}: {top_match['confidence']:.4f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"Summary: {correct_count}/{len(val_ground_truth)} correct ({correct_count/len(val_ground_truth)*100:.2f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29092344",
   "metadata": {},
   "source": [
    "### 12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed7706",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK 4: MATCHING PIPELINE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úì Matcher: Cosine Similarity\")\n",
    "print(f\"‚úì Gallery: {matcher.num_gallery} embeddings from {len(all_embeddings)} identities\")\n",
    "print(f\"\\nüìä RESULTS:\")\n",
    "print(f\"   Top-1 Accuracy: {accuracy['top_1_accuracy']:.4f} ({accuracy['top_1_accuracy']*100:.2f}%)\")\n",
    "print(f\"   Top-5 Accuracy: {accuracy['top_5_accuracy']:.4f} ({accuracy['top_5_accuracy']*100:.2f}%)\")\n",
    "print(f\"\\n‚öôÔ∏è CONFIGURATION:\")\n",
    "print(f\"   Threshold: {matcher.threshold}\")\n",
    "print(f\"   Top-K: {matcher.top_k}\")\n",
    "print(f\"\\nüí° RECOMMENDATION:\")\n",
    "print(f\"   Optimal Threshold: {optimal_threshold:.2f} (accuracy: {optimal_accuracy*100:.2f}%)\")\n",
    "print(f\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
