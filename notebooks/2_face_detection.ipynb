{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f8636a7",
   "metadata": {},
   "source": [
    "# Task 2: Face Detection\n",
    "## Implement YOLO v8 face detector and measure precision/recall metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7a856",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path('..').resolve()))\n",
    "from src.detection import FaceDetector\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ae539",
   "metadata": {},
   "source": [
    "### 2. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2618a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "BASE_PATH = Path('..').resolve()\n",
    "GALLERY_ALIGNED_PATH = BASE_PATH / 'data' / 'gallery_aligned'\n",
    "VALIDATION_PATH = BASE_PATH / 'data' / 'validation'\n",
    "MODEL_PATH = BASE_PATH / 'models' / 'yolov8n.pt'\n",
    "\n",
    "print(f\"Base path: {BASE_PATH}\")\n",
    "print(f\"Validation path: {VALIDATION_PATH}\")\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "print(f\"Validation path exists: {VALIDATION_PATH.exists()}\")\n",
    "\n",
    "# List validation images\n",
    "val_images = sorted(list(VALIDATION_PATH.glob('*.jpg')) + list(VALIDATION_PATH.glob('*.png')))\n",
    "print(f\"\\nValidation images found: {len(val_images)}\")\n",
    "if val_images:\n",
    "    print(f\"Sample: {val_images[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a04ad29",
   "metadata": {},
   "source": [
    "### 3. Initialize Face Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector\n",
    "detector = FaceDetector(model_path=str(MODEL_PATH), confidence=0.5)\n",
    "print(\"Face detector initialized!\")\n",
    "print(f\"Model: {detector.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5772da33",
   "metadata": {},
   "source": [
    "### 4. Test Detection on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on first validation image\n",
    "test_image = val_images[0]\n",
    "img = cv2.imread(str(test_image))\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(f\"Testing image: {test_image.name}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "\n",
    "# Detect faces\n",
    "detections = detector.detect(img)\n",
    "print(f\"\\nDetections found: {len(detections)}\")\n",
    "\n",
    "for i, det in enumerate(detections):\n",
    "    print(f\"\\nDetection {i+1}:\")\n",
    "    print(f\"  Bbox: {det['bbox']}\")\n",
    "    print(f\"  Confidence: {det['confidence']:.4f}\")\n",
    "    print(f\"  Area: {det['area']} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd248ff",
   "metadata": {},
   "source": [
    "### 5. Visualize Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw detections\n",
    "img_with_detections = img.copy()\n",
    "for det in detections:\n",
    "    x1, y1, x2, y2 = det['bbox']\n",
    "    confidence = det['confidence']\n",
    "    # Draw bounding box\n",
    "    cv2.rectangle(img_with_detections, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    # Draw confidence score\n",
    "    label = f\"{confidence:.2f}\"\n",
    "    cv2.putText(img_with_detections, label, (x1, y1 - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "img_rgb_detected = cv2.cvtColor(img_with_detections, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_rgb_detected)\n",
    "plt.title(f'Detections (Found {len(detections)} faces)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Detection visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7165fef",
   "metadata": {},
   "source": [
    "### 6. Run Detection on All Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detection on all validation images\n",
    "all_detections = {}\n",
    "detection_stats = []\n",
    "\n",
    "print(f\"Processing {len(val_images)} validation images...\\n\")\n",
    "\n",
    "for val_img_path in tqdm(val_images, desc=\"Detecting faces\"):\n",
    "    img = cv2.imread(str(val_img_path))\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    detections = detector.detect(img)\n",
    "    all_detections[val_img_path.name] = detections\n",
    "    \n",
    "    # Store stats\n",
    "    detection_stats.append({\n",
    "        'image': val_img_path.name,\n",
    "        'num_detections': len(detections),\n",
    "        'image_size': img.shape[:2],\n",
    "        'max_confidence': max([d['confidence'] for d in detections]) if detections else 0\n",
    "    })\n",
    "\n",
    "print(f\"\\nâœ“ Detection complete for {len(all_detections)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f52bf",
   "metadata": {},
   "source": [
    "### 7. Detection Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232875f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create statistics dataframe\n",
    "df_stats = pd.DataFrame(detection_stats)\n",
    "\n",
    "print(\"Detection Statistics:\")\n",
    "print(f\"\\nTotal validation images: {len(df_stats)}\")\n",
    "print(f\"Images with detections: {(df_stats['num_detections'] > 0).sum()}\")\n",
    "print(f\"Images without detections: {(df_stats['num_detections'] == 0).sum()}\")\n",
    "print(f\"\\nDetections per image:\")\n",
    "print(f\"  Min: {df_stats['num_detections'].min()}\")\n",
    "print(f\"  Max: {df_stats['num_detections'].max()}\")\n",
    "print(f\"  Mean: {df_stats['num_detections'].mean():.2f}\")\n",
    "print(f\"\\nConfidence scores:\")\n",
    "print(f\"  Min: {df_stats['max_confidence'].min():.4f}\")\n",
    "print(f\"  Max: {df_stats['max_confidence'].max():.4f}\")\n",
    "print(f\"  Mean: {df_stats['max_confidence'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\nDetailed results:\")\n",
    "print(df_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c757f6a6",
   "metadata": {},
   "source": [
    "### 8. Calculate Precision/Recall Metrics\n",
    "Note: Since validation set has 1 face per image (from Task 1), expected ground truth = 1 face per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each validation image, expected ground truth = 1 face\n",
    "# Calculate metrics assuming each image should have exactly 1 face detected\n",
    "\n",
    "metrics_per_image = []\n",
    "\n",
    "for val_img_path in val_images:\n",
    "    img = cv2.imread(str(val_img_path))\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    detections = all_detections.get(val_img_path.name, [])\n",
    "    \n",
    "    # Ground truth: 1 face per image (from Task 1 - already aligned)\n",
    "    ground_truth = [[10, 10, img.shape[1]-10, img.shape[0]-10]]  # Approximate full image as GT\n",
    "    \n",
    "    # If detections exist, we have at least one prediction\n",
    "    if detections:\n",
    "        # True Positive if at least 1 detection\n",
    "        tp = 1\n",
    "        fp = max(0, len(detections) - 1)  # Extra detections are false positives\n",
    "        fn = 0\n",
    "    else:\n",
    "        # No detection = False Negative\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 1\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else (1.0 if fn == 0 else 0.0)\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 1.0\n",
    "    \n",
    "    metrics_per_image.append({\n",
    "        'image': val_img_path.name,\n",
    "        'num_detections': len(detections),\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_per_image)\n",
    "\n",
    "# Overall metrics\n",
    "total_tp = df_metrics['tp'].sum()\n",
    "total_fp = df_metrics['fp'].sum()\n",
    "total_fn = df_metrics['fn'].sum()\n",
    "\n",
    "overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "f1_score = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DETECTION METRICS - OVERALL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Positive (TP): {total_tp}\")\n",
    "print(f\"False Positive (FP): {total_fp}\")\n",
    "print(f\"False Negative (FN): {total_fn}\")\n",
    "print(f\"\\nPrecision: {overall_precision:.4f}\")\n",
    "print(f\"Recall: {overall_recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f5ae0",
   "metadata": {},
   "source": [
    "### 9. Visualization of Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9bcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Detection count distribution\n",
    "axes[0, 0].bar(range(len(df_metrics)), df_metrics['num_detections'])\n",
    "axes[0, 0].set_xlabel('Image Index')\n",
    "axes[0, 0].set_ylabel('Number of Detections')\n",
    "axes[0, 0].set_title('Detections per Image')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# 2. Precision per image\n",
    "axes[0, 1].bar(range(len(df_metrics)), df_metrics['precision'], color='green', alpha=0.7)\n",
    "axes[0, 1].axhline(y=overall_precision, color='r', linestyle='--', label=f'Overall: {overall_precision:.2f}')\n",
    "axes[0, 1].set_xlabel('Image Index')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "axes[0, 1].set_title('Precision per Image')\n",
    "axes[0, 1].set_ylim([0, 1.1])\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Recall per image\n",
    "axes[1, 0].bar(range(len(df_metrics)), df_metrics['recall'], color='blue', alpha=0.7)\n",
    "axes[1, 0].axhline(y=overall_recall, color='r', linestyle='--', label=f'Overall: {overall_recall:.2f}')\n",
    "axes[1, 0].set_xlabel('Image Index')\n",
    "axes[1, 0].set_ylabel('Recall')\n",
    "axes[1, 0].set_title('Recall per Image')\n",
    "axes[1, 0].set_ylim([0, 1.1])\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# 4. Overall metrics summary\n",
    "axes[1, 1].axis('off')\n",
    "metrics_text = f\"\"\"\n",
    "FACE DETECTION METRICS\n",
    "{'='*40}\n",
    "\n",
    "Total Images: {len(df_metrics)}\n",
    "Images with Detections: {(df_metrics['num_detections'] > 0).sum()}\n",
    "Images without Detections: {(df_metrics['num_detections'] == 0).sum()}\n",
    "\n",
    "True Positives (TP): {total_tp}\n",
    "False Positives (FP): {total_fp}\n",
    "False Negatives (FN): {total_fn}\n",
    "\n",
    "Precision: {overall_precision:.4f}\n",
    "Recall: {overall_recall:.4f}\n",
    "F1-Score: {f1_score:.4f}\n",
    "\"\"\"\n",
    "axes[1, 1].text(0.1, 0.5, metrics_text, fontsize=12, family='monospace',\n",
    "                verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Metrics visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc811cc1",
   "metadata": {},
   "source": [
    "### 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45546de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK 2: FACE DETECTION - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nâœ“ Model: YOLO v8 (nano)\")\n",
    "print(f\"âœ“ Validation Set: {len(val_images)} images\")\n",
    "print(f\"âœ“ Confidence Threshold: 0.5\")\n",
    "print(f\"\\nðŸ“Š METRICS:\")\n",
    "print(f\"   Precision: {overall_precision:.4f} ({overall_precision*100:.2f}%)\")\n",
    "print(f\"   Recall: {overall_recall:.4f} ({overall_recall*100:.2f}%)\")\n",
    "print(f\"   F1-Score: {f1_score:.4f}\")\n",
    "print(f\"\\nâœ“ Faces correctly detected: {total_tp}/{total_tp + total_fn}\")\n",
    "print(f\"âœ“ False positives: {total_fp}\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
